{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook showing how transfer learning can be implemented in keras (tensorflow backend). \n",
    "\n",
    "When models are created/used they become part of the keras/tensorflow graph. Layers which are shared between models are not duplicated in the graph. Keras will get confused when it comes to training so it is important to have a clean graph.\n",
    "\n",
    "It is thefore useful to use keras.backend.clear_session() whenever moving between different training schemes or models. And important to transfer layer information through shared model objects (backbones) via model.save_weights() and model.load_weights() as shown in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#gan training script\n",
    "from models import ResNet, Discriminator, Classifier, ResGen, Unet, mnist_data\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mnist_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create models and test outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0417 12:12:53.746738 4551929280 base_layer.py:1790] Layer Discriminator is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "backbone = ResNet()\n",
    "discriminator = Discriminator(backbone)\n",
    "discriminator_predicitons_1 = discriminator(data.get_test()[0])\n",
    "discriminator.save_weights('discriminator_weights.npy')\n",
    "backbone.save_weights('backbone_pretrained_weights.npy')\n",
    "\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10000, 1), dtype=float32, numpy=\n",
       "array([[0.75502723],\n",
       "       [0.70718175],\n",
       "       [0.6879473 ],\n",
       "       ...,\n",
       "       [0.707958  ],\n",
       "       [0.6520088 ],\n",
       "       [0.79798913]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator_predicitons_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0417 12:13:04.407965 4551929280 base_layer.py:1790] Layer ResNet is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 12:13:14.763929 4551929280 base_layer.py:1790] Layer ResGen is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "backbone = ResNet()\n",
    "backbone(data.get_test()[0])\n",
    "generator = ResGen(backbone)\n",
    "# _ = generator.predict(data.get_test()[0])\n",
    "backbone.load_weights('backbone_pretrained_weights.npy')\n",
    "generator.save_weights('generator_weights.npy')\n",
    "rand_data_shape = ((50,) + (7,7) + (1,))\n",
    "random_noise_data = np.random.normal(size=rand_data_shape)\n",
    "generator_predicitons_1 = generator(random_noise_data)\n",
    "\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "backbone = ResNet()\n",
    "classifier = Classifier(backbone,10)\n",
    "classifier_predicitons_0 = classifier.predict(data.get_test()[0])\n",
    "backbone.load_weights('backbone_pretrained_weights.npy')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Classifier\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ResNet (ResNet)              multiple                  208080    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  25088     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  62730     \n",
      "=================================================================\n",
      "Total params: 295,898\n",
      "Trainable params: 282,010\n",
      "Non-trainable params: 13,888\n",
      "_________________________________________________________________\n",
      "Train on 10 samples\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 2s 198ms/sample - loss: 2.0936 - accuracy: 0.3000\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 5ms/sample - loss: 0.0215 - accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 6ms/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 5ms/sample - loss: 5.9512e-04 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 6ms/sample - loss: 3.9964e-04 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 6ms/sample - loss: 3.5613e-04 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 6ms/sample - loss: 3.2268e-04 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 6ms/sample - loss: 2.9036e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 6ms/sample - loss: 2.4664e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 6ms/sample - loss: 2.1290e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 6ms/sample - loss: 1.7979e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 6ms/sample - loss: 1.5543e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 6ms/sample - loss: 1.3408e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 6ms/sample - loss: 1.1510e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 6ms/sample - loss: 9.6866e-05 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 6ms/sample - loss: 8.2434e-05 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 6ms/sample - loss: 7.0624e-05 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 6ms/sample - loss: 6.1030e-05 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 6ms/sample - loss: 5.3461e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 6ms/sample - loss: 4.6798e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x141722828>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "classifier.summary()\n",
    "# classifier.fit(x=x_train,y=y_train,batch_size=6000,epochs=1, validation_data=(x_vali,y_vali),callbacks=[checkpoint])\n",
    "classifier.fit(x=data.get_debug()[0],y=data.get_debug()[1],batch_size=6000,epochs=20)\n",
    "# classifier.fit(x=data.get_train()[0],y=data.get_train()[1],batch_size=6000,epochs=1, validation_data=data.get_vali())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = classifier.get_backbone()\n",
    "backbone.save_weights('backbone_posttrained_weights.npy')\n",
    "classifier.save_weights('classifier_weights.h5')\n",
    "classifier_predicitons_1 = classifier.predict(data.get_test()[0])\n",
    "\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0417 12:13:30.551861 4551929280 base_layer.py:1790] Layer Discriminator is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "backbone = ResNet()\n",
    "discriminator = Discriminator(backbone)\n",
    "_ = discriminator(data.get_test()[0])\n",
    "discriminator.load_weights('discriminator_weights.npy')\n",
    "backbone.load_weights('backbone_posttrained_weights.npy')\n",
    "discriminator_predicitons_2 = discriminator(data.get_test()[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "backbone = ResNet()\n",
    "classifier = Classifier(backbone,10)\n",
    "_ = classifier.predict(data.get_test()[0])\n",
    "classifier.load_weights('classifier_weights.h5')\n",
    "backbone.load_weights('backbone_posttrained_weights.npy')\n",
    "classifier_predicitons_2 = classifier.predict(data.get_test()[0])\n",
    "\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0417 12:14:05.293900 4551929280 base_layer.py:1790] Layer ResNet is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "W0417 12:14:16.730381 4551929280 base_layer.py:1790] Layer ResGen is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "backbone = ResNet()\n",
    "backbone(data.get_test()[0])\n",
    "generator = ResGen(backbone)\n",
    "generator.load_weights('generator_weights.npy')\n",
    "backbone.load_weights('backbone_posttrained_weights.npy')\n",
    "generator_predicitons_2 = generator(random_noise_data)\n",
    "\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with previous predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_diff = discriminator_predicitons_1 - discriminator_predicitons_2\n",
    "classifier_diff = classifier_predicitons_1 - classifier_predicitons_2\n",
    "generator_diff = generator_predicitons_1 - generator_predicitons_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between generator model with trained and untrained backbone \n",
    "\n",
    "should be nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2747.7236"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(generator_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between predicted and loaded classifier model\n",
    "\n",
    "should be zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(classifier_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between discriminator model with trained and untrained backbone \n",
    "\n",
    "should be nonzero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-522.9665"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(discriminator_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Test if model backbone or submodels are also loaded correctly with load_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "backbone = ResNet()\n",
    "classifier = Classifier(backbone,10)\n",
    "_ = classifier.predict(data.get_test()[0])\n",
    "classifier.load_weights('classifier_weights.h5')\n",
    "classifier_predicitons_3 = classifier.predict(data.get_test()[0])\n",
    "\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should be zero if submodels are loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(classifier_predicitons_2 - classifier_predicitons_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing backbone weights after model is loaded. This change should mean that the classifier predictions change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "backbone = ResNet()\n",
    "# backbone.load_weights('backbone_pretrained_weights.npy')\n",
    "classifier = Classifier(backbone,10)\n",
    "_ = classifier.predict(data.get_test()[0])\n",
    "classifier.load_weights('classifier_weights.h5')\n",
    "backbone.load_weights('backbone_pretrained_weights.npy')\n",
    "classifier_predicitons_4 = classifier.predict(data.get_test()[0])\n",
    "\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4868717e-06"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(classifier_predicitons_3 - classifier_predicitons_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
